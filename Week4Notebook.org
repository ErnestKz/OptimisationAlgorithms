#+AUTHOR:Ernests Kuznecovs - 17332791 - kuznecoe@tcd.ie
#+Date:16th February 2022
#+Title:Optimisation Algorithms - Week 4 Assignment

#+begin_export latex
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
#+end_export

* Preamble :noexport:
#+PROPERTY: header-args:python :session a2
#+PROPERTY: header-args:python+ :async yes
#+PROPERTY: header-args:python+ :eval never-export
#+PROPERTY: header-args:elisp :eval never-export
#+EXCLUDE_TAGS: noexport

#+LaTeX_HEADER: \usepackage{listings}
#+LaTeX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \usepackage{minted}
#+LaTeX_HEADER: \usepackage[a4paper, total={6.7in, 10.5in}]{geometry}

#+LaTeX_HEADER: \usepackage{caption}
#+LaTeX_HEADER: \newcommand\figwidth{0.48}

#+begin_src elisp :results none :exports none
(setq-local org-image-actual-width '(512))
(setq-local org-confirm-babel-evaluate nil)
(setq-local org-src-preserve-indentation 't)

(setq org-latex-listings t)
(setq org-latex-prefer-user-labels t)
#+end_src

#+begin_src python :results none :exports none :tangle ./Week4Src.py
import matplotlib as mpl
mpl.rcParams['figure.dpi'] = 200
mpl.rcParams['figure.facecolor'] = '1'
import matplotlib.pyplot as plt
#+end_src

#+begin_src python :results none :exports none :tangle ./Week4Src.py
def plot_y_vary_param(inputs, comparing):
    i = inputs[0]
    f = i['f']
    function_name = f.function_name
    function_latex = f.latex()
    
    opt_alg = i['algorithm']
    algorithm_name = opt_alg.algorithm_name

    hyperparams = (opt_alg.hyperparameters + ['x0'])
    hyperparams.remove(comparing)
    
    hs = hyperparams_string(i, hyperparams)
    top = (rf'{algorithm_name} on ${function_latex}$ varying {comparing}')
    title_string = top + " \n" +hs

    fig, ax = plt.subplots()
    ax.set_title(title_string)
    ax.set_ylabel(f'${function_name}$')
    ax.set_xlabel(r'$i$')

    rangei = 50
    legend_labels = []
    for (X, Y, var) in dicts_collect(("X", "Y", comparing), inputs):
        ax.plot(range(len(Y)), Y, linewidth=2.0)
        legend_labels += [(comparing + ": " + str(var))]
    ax.legend(legend_labels)
    return ax

def hyperparams_string(inputs, hyperparams):
    string = ""
    for p in hyperparams:
        string += f"{p}={inputs[p]}, "
    return string[0:-2]

def dicts_collect(keys, dicts):
    values = []
    for dict in dicts:
        values += [[dict[key] for key in keys]]
    return values
#+end_src

#+begin_src python :results none :exports none :tangle ./Week4Src.py
# import OptimisationAlgorithmToolkit
from OptimisationAlgorithmToolkit.Function import OptimisableFunction
from OptimisationAlgorithmToolkit import Algorithms
from OptimisationAlgorithmToolkit import DataType
import importlib
importlib.reload(Algorithms)
importlib.reload(DataType)
from OptimisationAlgorithmToolkit.Algorithms import Polyak, Adam, HeavyBall, RMSProp, Adagrad, ConstantStep
from OptimisationAlgorithmToolkit.DataType import meta, create_labels, get_titles
#+end_src

* Obtaining Functions
$\frac{\partial f_1}{\partial x_{1}}=12 \left(x_{1} - 9\right)^{3}, \frac{\partial f_1}{\partial x_{2}}=10 x_{2} - 90$
$f_1(x_{1},x_{2}) = 3 \left(x_{1} - 9\right)^{4} + 5 \left(x_{2} - 9\right)^{2}$

- $f_2(x, y) = 5 \left|{y - 9}\right| + \max\left(0, x - 9\right)$
  - $\frac{df_{2}}{dx}(x,y) = \theta\left(x - 9\right)$ - this is a Heaviside function
  - $\frac{df_{2}}{dy}(x,y) = 5 \operatorname{sign}{\left(y - 9 \right)}$

** Code :noexport:
#+begin_src python :results none :exports none :tangle ./Week4Src.py
from sympy import symbols, Max, Abs

x1, x2 = symbols('x1 x2', real=True)
sym_f1 = 3 * (x1-9)**4 + 5 * (x2-9)**2
f1 = OptimisableFunction(sym_f1, [x1, x2], "f_1")

sym_f2 = Max(x1-9 ,0) + 5 * Abs(x2-9)
f2 = OptimisableFunction(sym_f2, [x1, x2], "f_2")
#+end_src

* (a) Implementing Optimisation Aglorithms
** Polyak Step Size
- $\alpha = \frac{f(x) - f^*}{\Delta f(x)^T \Delta f(x) + \epsilon}$
- $x$ is a vector
- $[\frac{\partial f}{\partial x_1}(x), \frac{\partial f}{\partial x_2} (x), \ldots, \frac{\partial f}{\partial x_n}(x)] = \Delta f(x)$
- $\Delta f(x)^{T} \Delta f(x) = \sum\limits_{i=1}^{n} \frac{\partial f}{\partial x_i} (x)^2$
** Adagrad step

$\alpha_x = \frac{a_0}{\sqrt{ \frac{df}{dx} (\vec{x}_0)^2 + \frac{df}{dx}(\vec{x}_1)^2 + \hdots + \frac{df}{dx}(\vec{x}_{t-1})^{2}} + \epsilon} = \frac{\alpha_0}{\sqrt{\sum\limits_{i=1}^{t-1} \frac{df}{dx}(x_i)^2}+\epsilon}$
$t=1$
$\alpha_1 = \frac{a_0}{\sqrt{ \frac{df}{dx_1} (\vec{x}_0)^2} + \epsilon}$
$\alpha_2 = \frac{a_0}{\sqrt{ \frac{df}{dx_2} (\vec{x}_0)^2} + \epsilon}$

$t=2$
$\alpha_1 = \frac{a_0}{\sqrt{ \frac{df}{dx_1} (\vec{x}_0)^2 + \frac{df}{dx_2}(\vec{x}_1)^2}+ \epsilon}$
$\alpha_2 = \frac{a_0}{\sqrt{ \frac{df}{d\vec{x}_2} (\vec{x}_0)^2 + \frac{df}{dx_2}(\vec{x}_1)^2}  + \epsilon} }$

so we can just hold $\frac{df}{dx_1} (\vec{x}_0)^2 + \frac{df}{dx_2}(\vec{x}_1)^2$ bit in a variable
and then sum $\frac{df}{dx_3}(\vec{x}_3)^2$ onto the variable when it comes
and we can discard $\vec{x}_0, \vec{x}_1$, as its not used anywhere else

so for multiple partials, can hold the sums in a vector
upon each iteration calculate the new partial squared for each partial(this will give us a vector) and then sum each to the according sum in the vector

** RMSProp

$a_t = \frac{ a_0 }{ \sqrt{(1 - \beta) \beta^t \frac{df}{dx}(x_0)^2 + (1 - \beta) \beta^{t-1} \frac{df}{dx}(x_1)^2 + \hdots + (1 - \beta) \frac{df}{dx} (x_{t-1})^2} + \epsilon}$
$0 < \beta \leq 1$

- We only need to keep track of the sum, as the we dont use x0 anymore.
- We can simply multiply the sum with Beta to scale it and it will have the same effect.

** Heavy Ball / Polyak Momentum

** Adam
Posible to get rid of the betas with polyak?

Adam $\approx$ RMSprop + heavy ball
$m_{t+1} = \beta_1 m_t + (1 - \beta_1) \Delta f(x_t)$ heavy ball bit
- note, there is no minimising weight on the most recent term, the term is applied only on the last ones
  
$v_{t+1} = \beta_2 v_t + (1 - \beta_2)[ \frac{\partial f}{\partial x_1} (x_t)^2, \frac{\partial f}{\partial x_2} (x_t)^{2}, \hdots , \frac{\partial f}{\partial x_n}(x_t)^2 ]$ this is rms bit, it is being summmed through each step
$\hat{m}= \frac{m_{t+1}}{(1 - \beta^t_1)}, \hat{v}= \frac{v_{t+1}}{(1 - \beta^t_2)}$
$x_{t+1} = x_{t} - \alpha [\frac{\hat{m}}{\sqrt{\hat{v_1}} + \epsilon}, \frac{\hat{m}}{\sqrt{\hat{v_2}} + \epsilon},\hdots,\frac{\hat{m}}{\sqrt{\hat{v_n}} + \epsilon}]$
$m$ is running average of gradient $\Delta f(x_t)$
$v$ is running average of square gradients

$\hat{v}_{i}$ is indexing/picking out elements from the vector of updates.


Similary to heavy ball, large step size that spans a lot of the function does well.
- It's like feeding a lot of information to the algorithm and the algorithm can take advantage of that.

$[ (1 - \beta_1)\frac{\partial f}{\partial x_1} (x_t), (1 - \beta_1)\frac{\partial f}{\partial x_2} (x_t), \hdots , (1 - \beta_1)\frac{\partial f}{\partial x_n}(x_t) ]$

$(1-\beta_{1})\Delta f(x_t) = [ (1 - \beta_1)\frac{\partial f}{\partial x_1} (x_t) + (1 - \beta_1)\frac{\partial f}{\partial x_2} (x_t) + \hdots  + (1 - \beta_1)\frac{\partial f}{\partial x_n}(x_t) ]$ ? 

* (b) Inspecting Algorithm Behaviour
- To save space plot multiple curves of function value vs iteration number on single plot.
  - step size vs iteration
  - y value vs iteration
  - contour plot

** (i) $\alpha$ and $\beta$ in RMSProp

** (ii) $\alpha$ and $\beta$ in Heavy Ball
** (iii) $\alpha$, $\beta_1$ and $\beta_2$ in RMSProp

** Code :noexport:
*** Test quadratic

#+begin_src python :results replace :exports none :tangle ./Week4Src.py
outputs = ConstantStep.set_parameters(
    x0=[[1]],
    f=f_quadratic,
    iters=50,
    alpha=0.1).run()

plot_y_vary_param(outputs, "x0").semilogy()
#+end_src

#+begin_src python :results replace :exports none :tangle ./Week4Src.py
outputs2 = Adagrad.set_parameters(
    x0=[[1], [2]],
    f=f_quadratic,
    iters=50,
    alpha0=[0.2, 0.5, 0.8],               # this should determine each records label
    eps=1e-5).run()
# print(outputs)                            # output should probably contain labels
                                          # and i control the plot title rather than the output

# plot_y_vary_param(outputs, "alpha0").semilogy()   # can have utility functions to extract title stuff and strings
#+end_src

#+RESULTS:

#+begin_src python :results replace :exports none :tangle ./Week4Src.py
a =  set({1, 2, 3})
b = set({2, 3})
a - b 
#+end_src

#+RESULTS:
| 1 |

#+begin_src python :results replace :exports none :tangle ./Week4Src.py
x = symbols('x', real=True)
sym_f_quadratic = x**2
f_quadratic = OptimisableFunction(sym_f_quadratic, [x], "f_q")

print(RMSProp.all_parameters)

outputs2 = Adagrad.set_parameters(
    x0=[[1], [2]],
    f=f_quadratic,
    iters=50,
    alpha0=[0.2, 0.5, 0.8],               # this should determine each records label
    eps=1e-5).run()

RMSProp.set_parameters(
    x0=[1],
    f=f_quadratic,
    iters=50,
    alpha0=0.06,
    beta=[0.1, 0.2, 0.9],
    eps=1e-5)
outputs = RMSProp.run()
print(outputs[0]['Y'])
# ax = plot_y_vary_param(outputs, "beta")
# ax.semilogy()
a = outputs + outputs2
create_labels(a)
t = get_titles(a)
print(t)
print(a[4]['label'])
#+end_src

#+RESULTS:
: ('x0', 'f', 'alpha0', 'beta', 'eps', 'iters')
: [1, 0.7744, 0.6670884451118795, 0.5728810775648908, 0.48635568503715226, 0.4070152686083506, 0.33480471700253883, 0.2697113765903326, 0.21172517738577293, 0.1608340066675227, 0.11702221512889699, 0.08026871560573763, 0.05054356526374296, 0.027800977662262735, 0.011962542840321638, 0.0028652985628994623, 6.210885341954861e-06, 2.4681843104832683e-05, 0.001072758984218594, 0.0009168270280496842, 0.000872149991968518, 0.0009172354785382298, 0.0008901654698807918, 0.0009046112476984058, 0.0008972155781964292, 0.0009009468703284158, 0.0008990759547489987, 0.0009000119778336547, 0.0008995441525329219, 0.0008997778921562405, 0.0008996611282174754, 0.0008997194542682174, 0.0008996903199956145, 0.0008997048726588406, 0.000899697603592074, 0.000899701234492874, 0.0008996994208585365, 0.0008997003267684718, 0.0008996998742667407, 0.0008997001002912125, 0.000899699987392064, 0.0008997000437851514, 0.0008997000156168229, 0.0008997000296868936, 0.0008997000226588979, 0.0008997000261693792, 0.0008997000244158951, 0.0008997000252917597, 0.0008997000248542655, 0.0008997000250727947, 0.0008997000249636385]
: {'RMSProp': 'RMSProp: x0=[1] iters=50 eps=1e-05 alpha0=0.06', 'Adagrad': 'Adagrad: iters=50 eps=1e-05'}
: Adagrad 	 x0=[1] alpha0=0.5

*** RMS
#+begin_src python :results replace :exports none :tangle ./Week4Src.py
print(RMSProp.all_parameters)
RMSProp.set_parameters(
    x0=[1, 1],
    f=f1,
    iters=10,
    alpha0=0.05,
    beta=[0.1, 0.2, 0.9],
    eps=0.0001)
outputs = RMSProp.run()
print(outputs[0]['Y'])
plot_y_vary_param(outputs, "beta")
#+end_src

#+RESULTS:
:RESULTS:
: ('x0', 'f', 'alpha0', 'beta', 'eps', 'iters')
: [12608, 24041835038.028812, 24024899458.500347, 24008761126.55103, 23992703838.156597, 23976661842.626972, 23960628616.26208, 23944603504.804234, 23928586440.412037, 23912577413.880844, 23896576421.870003]
[[file:./.ob-jupyter/036da439b7425b723533f794f119d34332bbaa9e.png]]
:END:

*** Heavy Ball
*** RMSProp
*** Contour Plot
#+begin_src python :results replace :exports code :tangle ./Week4Src.py
# countour plot
delta = 0.2
x1s = np.arange(0, 15, delta)
x2s = np.arange(0, 15, delta)
X1, X2 = np.meshgrid(x1s, x2s)
# for each pair of the x1s and x2s, there is a y value

# Z1 = np.exp(-X1**2 - X2**2)
# Z2 = np.exp(-(X1 - 1)**2 - (X2 - 1)**2)
# Z = (Z1 - Z2) * 2

print(x1s.shape)
print(x2s.shape)
print(X1.shape)
print(X2.shape)
print(Z.shape)
from matplotlib import ticker, cm
# Z = np.vectorize(f1l)(X1, X2)
Z = np.vectorize(f1l)(X1, X2)
fig, ax = plt.subplots()
CS = ax.contourf(X1, X2, Z,
                cmap=cm.PuBu_r,
                locator=ticker.LogLocator()
                 )
# manual_locations = [
#     (-1, -1.4), (-0.62, -0.7), (-2, 0.5), (1.7, 1.2), (2.0, 1.4), (2.4, 1.7)]
ax.clabel(CS, inline=True, fontsize=10,
          # manual=manual_locations
          
          )
cbar = fig.colorbar(CS)
ax.set_title('Simplest default with labels')
#+end_src

* (c) Optimising ReLu - $Max(0, x)$
** (i) Initial Condition $x = -1$
** (ii) Initial Condition $x = +1$
** (iii) Initial Condition $x =+100$
